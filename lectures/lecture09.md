### Lecture: 9. Decision Trees, Random Forests
#### Date: Nov 26
#### Slides: https://ufal.mff.cuni.cz/~courses/npfl129/2425/slides/?09
#### Reading: https://ufal.mff.cuni.cz/~courses/npfl129/2425/slides.pdf/npfl129-2425-09.pdf,PDF Slides
#### Lecture assignment: decision_tree
#### Lecture assignment: random_forest
#### Questions: #lecture_9_questions

The lecture will be exceptionally during the slots for the practicals! (Czech lecture on Tuesday, 15:40, English lecture on Thursday 9:00)

**Learning objectives.** After the lecture you shoud be able to

- Implement Decision Trees and Random Forests for classification and regression

- Explain how the splitting criterion depend on optimized loss function

- Tell how Random Forests differ from Gradient Boosted Decision Trees

**Covered topics** and where to find more:

- Decision trees [Section 14.4 of PRML]
  - [Decision trees demo](https://mlu-explain.github.io/decision-tree/) by Jared Wilber & Lucía Santamaría

- Random forests
  - [Random forets demo](https://mlu-explain.github.io/random-forest/) by Jenny Yeon & Jared Wilber
